:path: 01_database_cleanup

ifdef::rootpath[]
:imagesdir: {rootpath}{path}
endif::rootpath[]

== Datenbereinigung: Konzentration auf die potentesten Daten

Um die Analyseergebnisse zu optimieren und aussagekräftige Schlussfolgerungen aus den Daten zu ziehen, wurde eine gründliche Datenbereinigung durchgeführt. Dabei wurden Datensätze herausgefiltert, die aufgrund von Inkonsistenzen oder fehlender Relevanz für die Analyse untauglich waren.

=== Entfernen von unvollständig dokumentierten Losen

Da unser Datensatz ab dem 22.09.2022 alle Vorgänge dokumentiert, die Produktion allerdings schon davor lief, gibt es im Datensatz Lots, die vor Beginn der Dokumentierung begonnen wurden. Diese sind jene Lots deren erste Erscheinung einen Operations-Counter größer als 1 hat. Dabei handelt es sich um **
include::count_items_lots_that_do_not_start_with_operation_1.csv[]
Lose** und es werden **
include::count_rows_lots_that_do_not_start_with_operation_1.csv[]
Zeilen** aus der Datenbank entfernt.

=== Entfernen aller Lose, die mehrere Routen durchlaufen

Die Daten enthalten Lose, die mehrere Routen durchlaufen. Da ein Los dabei einzelne Operationen von einer Route mit Schritten einer anderen Route vermischt, werden diejenigen Lose, die mehrere Routen durchlaufen aus den Daten entfernt. Es handelt sich dabei um **
include::count_rows_lots_that_run_several_routes.csv[]
Lose**, wodurch **
include::count_items_lots_that_run_several_routes.csv[]
Zeilen** entfernt werden.

=== Entfernen aller duplizierten Operationen
TODO

'''
Durch die Anwendung dieser Filterkriterien wurde der ursprüngliche Datensatz bereinigt. Durch diese Bereinigungsmaßnahmen reduziert sich die Datenmenge auf **
include::count_leftover_rows.csv[]
verbleibende Zeilen**, die für die weitere Analyse verwendet werden können. Durch diese Datenbereinigung erhoffen wir uns qualitativ bessere Ergebnisse in der weitergehenden Analyse.